{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import itertools \n",
    "np.random.seed(0)\n",
    "\n",
    "class Parameters:\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_true_dist_parameters(len_x, lb, ub):\n",
    "        elements = [0,1]\n",
    "        dict_parameters = {\"x1\": {(): np.random.uniform(lb,ub)}}\n",
    "        for k in range(2,len_x+1):\n",
    "            permutations = list(itertools.product(elements, repeat=k-1))\n",
    "            dict_parameters[\"x\"+str(k)] = {perm: np.random.uniform(lb,ub) for perm in permutations}\n",
    "        return dict_parameters\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_logsitc_parameters(len_x, lb, ub):\n",
    "        elements = [0,1]\n",
    "        dict_parameters = {\"x1\":{\"bias\": np.random.uniform(lb, ub)}}\n",
    "\n",
    "        for k in range(2, len_x+1):\n",
    "            dict_parameters[\"x\"+str(k)] = {\"bias\": np.random.uniform(lb,ub)}\n",
    "            for j in range(1,k):\n",
    "                dict_parameters[\"x\"+str(k)][\"x\"+str(j)]= np.random.uniform(lb,ub)\n",
    "        return dict_parameters\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Number of paramerters of the True distribution \n",
    "\n",
    "$$\n",
    "p(x_1, x_2, x_3, \\dots, x_5) = p(x_1) \\cdot p(x_2 \\mid x_1) \\cdot p(x_3 \\mid x_1, x_2) \\cdots p(x_n \\mid x_1, x_2, \\dots, x_{4})\n",
    "$$\n",
    "\n",
    "#Total number of parameters x can take [0,1]\n",
    "\n",
    "The total number of parameters is:\n",
    "\n",
    "$$\n",
    "1 + 2 + 2^2 + 2^3 + 2^4 = 31\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x1': {(): 0.5488135039273248},\n",
       " 'x2': {(0,): 0.7151893663724195, (1,): 0.6027633760716439},\n",
       " 'x3': {(0, 0): 0.5448831829968969,\n",
       "  (0, 1): 0.4236547993389047,\n",
       "  (1, 0): 0.6458941130666561,\n",
       "  (1, 1): 0.4375872112626925},\n",
       " 'x4': {(0, 0, 0): 0.8917730007820798,\n",
       "  (0, 0, 1): 0.9636627605010293,\n",
       "  (0, 1, 0): 0.3834415188257777,\n",
       "  (0, 1, 1): 0.7917250380826646,\n",
       "  (1, 0, 0): 0.5288949197529045,\n",
       "  (1, 0, 1): 0.5680445610939323,\n",
       "  (1, 1, 0): 0.925596638292661,\n",
       "  (1, 1, 1): 0.07103605819788694},\n",
       " 'x5': {(0, 0, 0, 0): 0.08712929970154071,\n",
       "  (0, 0, 0, 1): 0.02021839744032572,\n",
       "  (0, 0, 1, 0): 0.832619845547938,\n",
       "  (0, 0, 1, 1): 0.7781567509498505,\n",
       "  (0, 1, 0, 0): 0.8700121482468192,\n",
       "  (0, 1, 0, 1): 0.978618342232764,\n",
       "  (0, 1, 1, 0): 0.7991585642167236,\n",
       "  (0, 1, 1, 1): 0.46147936225293185,\n",
       "  (1, 0, 0, 0): 0.7805291762864555,\n",
       "  (1, 0, 0, 1): 0.11827442586893322,\n",
       "  (1, 0, 1, 0): 0.6399210213275238,\n",
       "  (1, 0, 1, 1): 0.1433532874090464,\n",
       "  (1, 1, 0, 0): 0.9446689170495839,\n",
       "  (1, 1, 0, 1): 0.5218483217500717,\n",
       "  (1, 1, 1, 0): 0.4146619399905236,\n",
       "  (1, 1, 1, 1): 0.26455561210462697}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parameters().generate_true_dist_parameters(len_x=5, lb = 0, ub = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Number of paramerters of the logistic approximation of the conditional probability \n",
    "\n",
    "$$\n",
    "p(x_1, x_2, x_3, \\dots, x_5) = p(x_1) \\cdot p(x_2 \\mid x_1) \\cdot p(x_3 \\mid x_1, x_2) \\cdots p(x_n \\mid x_1, x_2, \\dots, x_{4})\n",
    "$$\n",
    "\n",
    "#Total number of parameters x can take [0,1]\n",
    "$$\n",
    "p(x_1, x_2, x_3, \\dots, x_5) \\approx \\sigma(w_1^T x_1 + b_1) \\cdot \\sigma(w_2^T x_2 + b_2) \\cdot \\sigma(w_3^T x_3 + b_3) \\cdots \\sigma(w_5^T x_5 + b_5)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "The total number of parameters is:\n",
    "\n",
    "$$\n",
    "1 + 2 + 3 + 4 + 5 = 15\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x1': {'bias': 0.7742336894342167},\n",
       " 'x2': {'bias': 0.45615033221654855, 'x1': 0.5684339488686485},\n",
       " 'x3': {'bias': 0.018789800436355142,\n",
       "  'x1': 0.6176354970758771,\n",
       "  'x2': 0.6120957227224214},\n",
       " 'x4': {'bias': 0.6169339968747569,\n",
       "  'x1': 0.9437480785146242,\n",
       "  'x2': 0.6818202991034834,\n",
       "  'x3': 0.359507900573786},\n",
       " 'x5': {'bias': 0.43703195379934145,\n",
       "  'x1': 0.6976311959272649,\n",
       "  'x2': 0.06022547162926983,\n",
       "  'x3': 0.6667667154456677,\n",
       "  'x4': 0.6706378696181594}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generating logistic parameters\n",
    "parameter = Parameters().generate_logsitc_parameters(len_x=5, lb = 0, ub = 1)\n",
    "#lets assume that this is the distribution we are planning acheieve and this is our curret approx, true distribtion which redcues our parameters \n",
    "parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Distribution provides an exact representation but becomes computationally infeasible as \\( n \\) grows due to exponential parameter growth.\n",
    "\n",
    "Logistic Approximation offers a more scalable approach, reducing the parameter count significantly while maintaining sufficient flexibility.\n",
    "\n",
    "These methods illustrate the trade-off between accuracy and efficiency in probabilistic modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating 1 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample : [1, 1, 1, 1, 1], Sample probability : 0.33752692635670706, \n",
      "Chain probability : [0.6844360133921935, 0.7358645994418772, 0.7770437377025466, 0.9309908455336089, 0.9263749132521876]\n"
     ]
    }
   ],
   "source": [
    "#Geneating a sample from the distribution \n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "\n",
    "def get_a_sample(parameters):\n",
    "\n",
    "    x_sample = []\n",
    "    p_chain = []\n",
    "    prob = 1.0\n",
    "\n",
    "    for i in range(len(parameters)):\n",
    "        z = parameters[\"x\"+str(i+1)][\"bias\"]\n",
    "        for k in range(1,i+1):\n",
    "            z += x_sample[k-1]*parameters[\"x\"+str(i+1)][\"x\"+str(k)]\n",
    "        p_est = sigmoid(z)\n",
    "\n",
    "        s_i = np.random.binomial(1,p_est)\n",
    "        x_sample += [s_i]\n",
    "        prob *= p_est\n",
    "        p_chain += [float(p_est)]\n",
    "    return x_sample, prob, p_chain\n",
    "    \n",
    "\n",
    "sample, probability , chain = get_a_sample(parameters=parameter)\n",
    "\n",
    "print(f'Sample : {sample}, Sample probability : {probability}, ')\n",
    "print(f'Chain probability : {chain}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating n Samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1],\n",
       " [0, 1, 0, 1, 0],\n",
       " [1, 0, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1],\n",
       " [1, 1, 0, 1, 1]]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generating n samples \n",
    "\n",
    "def generate_n_samples(num_samples, parameters):\n",
    "    n_samples = []\n",
    "    for num in range(num_samples):\n",
    "        sample, _, _ = get_a_sample(parameters)\n",
    "        n_samples += [sample]\n",
    "    return n_samples\n",
    "    \n",
    "\n",
    "generate_n_samples(num_samples=10, parameters = parameter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x1': {'bias': 0},\n",
       " 'x2': {'bias': 0, 'x1': 0},\n",
       " 'x3': {'bias': 0, 'x1': 0, 'x2': 0},\n",
       " 'x4': {'bias': 0, 'x1': 0, 'x2': 0, 'x3': 0},\n",
       " 'x5': {'bias': 0, 'x1': 0, 'x2': 0, 'x3': 0, 'x4': 0}}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initial_derivative(len_samples):\n",
    "    dict_parameters = {}\n",
    "    dict_parameters = {\"x1\":{\"bias\": 0}}\n",
    "    for k in range(2, len_samples+1):\n",
    "            dict_parameters[\"x\"+str(k)] = {\"bias\": 0}\n",
    "            for j in range(1,k):\n",
    "                dict_parameters[\"x\"+str(k)][\"x\"+str(j)]= 0\n",
    "\n",
    "    return dict_parameters  \n",
    "\n",
    "init_derivative_value  = initial_derivative(len_samples=5)\n",
    "init_derivative_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 {'bias': 0}\n",
      "x2 {'bias': 0, 'x1': 0}\n",
      "x3 {'bias': 0, 'x1': 0, 'x2': 0}\n",
      "x4 {'bias': 0, 'x1': 0, 'x2': 0, 'x3': 0}\n",
      "x5 {'bias': 0, 'x1': 0, 'x2': 0, 'x3': 0, 'x4': 0}\n"
     ]
    }
   ],
   "source": [
    "for key,value in init_derivative_value.items():\n",
    "    print(key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
